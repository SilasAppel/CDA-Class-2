{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilasAppel/CDA-Class-2/blob/main/04_CDA_HH_midterm_synthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cultural Data Analysis\n",
        "\n",
        "Synthesis\n",
        "Week 01 - Week 04"
      ],
      "metadata": {
        "id": "7CC34uuNzNxY"
      },
      "id": "7CC34uuNzNxY"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "76a4e150-cc6f-4878-a32b-e78a1d6426ae",
      "metadata": {
        "id": "76a4e150-cc6f-4878-a32b-e78a1d6426ae"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import os, re, csv\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7010dda9-acc5-4d90-b175-90012564d13c",
      "metadata": {
        "id": "7010dda9-acc5-4d90-b175-90012564d13c"
      },
      "source": [
        "## Loading the datasets: heritage homes webistes\n",
        "\n",
        "The dataset is stored in a shared google drive:\n",
        "https://drive.google.com/drive/folders/11Shm0edDOiWrOe56fzJQRZi-v_BPSW8E?usp=drive_link\n",
        "\n",
        "Add it to your drive.\n",
        "\n",
        "To access it, load your gdrive in 'Files' (see left pane of the notebook in google colab) and navigate to the shared folder. You may need to click on 'refresh' to make it appear on the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d42429d3-63fe-4b79-b341-160057e5dcbc",
      "metadata": {
        "id": "d42429d3-63fe-4b79-b341-160057e5dcbc",
        "outputId": "eb813f66-2632-4b3b-c7ae-1cb4b4d41b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the github repository files where this notebook is stored to the available files. This will make it easier to import stopwords, url lists and other additional data we need."
      ],
      "metadata": {
        "id": "_WYOlRWhaBwf"
      },
      "id": "_WYOlRWhaBwf"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jazoza/cultural-data-analysis"
      ],
      "metadata": {
        "id": "F-MaBtlTaAgI"
      },
      "id": "F-MaBtlTaAgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import all datasets (4 countries)\n",
        "\n",
        "You will have all datasets available for analysis and comparison, mapped in the following way:\n",
        "\n",
        "> df0 - Dutch dataset\n",
        "\n",
        "> df1 - UK dataset\n",
        "\n",
        "> df2 - German dataset\n",
        "\n",
        "> df3 - French dataset"
      ],
      "metadata": {
        "id": "ukRXJgSvn-yx"
      },
      "id": "ukRXJgSvn-yx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Country code: change here between 'NL' and 'UK'\n",
        "cc_list = ['NL', 'UK', 'DE', 'FR']"
      ],
      "metadata": {
        "id": "Qu6K9f2Vo6i_"
      },
      "id": "Qu6K9f2Vo6i_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = '/content/gdrive/MyDrive/CDA/'"
      ],
      "metadata": {
        "id": "9fnHB7XSo89i"
      },
      "id": "9fnHB7XSo89i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import scraped json data into 4 separate dataframes\n",
        "df0=pd.read_json(gdrive_path+cc_list[0]+'_dataset_website-content-crawler.json')\n",
        "# select columns for analysis: url, text, metadata\n",
        "df0=df0[['url','text','metadata']]\n",
        "\n",
        "df1=pd.read_json(gdrive_path+cc_list[1]+'_dataset_website-content-crawler.json')\n",
        "# select columns for analysis: url, text, metadata\n",
        "df1=df1[['url','text','metadata']]\n",
        "\n",
        "df2=pd.read_json(gdrive_path+cc_list[2]+'_dataset_website-content-crawler.json')\n",
        "# select columns for analysis: url, text, metadata\n",
        "df2=df2[['url','text','metadata']]\n",
        "\n",
        "df3=pd.read_json(gdrive_path+cc_list[3]+'_dataset_website-content-crawler.json')\n",
        "# select columns for analysis: url, text, metadata\n",
        "df3=df3[['url','text','metadata']]\n",
        "\n",
        "df0.head()\n"
      ],
      "metadata": {
        "id": "8K9APfwUo4Up"
      },
      "id": "8K9APfwUo4Up",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join all pages from a domain to an entry in the analysis. To do this, add a new column which will contain only the main domain name."
      ],
      "metadata": {
        "id": "7yB3vYA7pGpq"
      },
      "id": "7yB3vYA7pGpq"
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extract the main domain from the url in the dataset\n",
        "def extract_main_domain(url):\n",
        "    if not isinstance(str(url), str):\n",
        "        print('NOT VALID',url)\n",
        "        return None\n",
        "    match = re.findall('(?:\\\\w+\\\\.)*\\\\w+\\\\.\\\\w*', str(url)) #'www\\.?([^/]+)'\n",
        "    return match[0].lstrip('www.') if match else None"
      ],
      "metadata": {
        "id": "sczGS62Oo8z6"
      },
      "id": "sczGS62Oo8z6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column 'domain' and fill it by applying the extract_main_domain function to the 'url' column\n",
        "\n",
        "# first, create a mapping of dataframes which could be addressed in a loop\n",
        "df_dict = {'0':df0, '1':df1, '2':df2, '3':df3}\n",
        "\n",
        "# then, loop through the df_dict to update each dataframe\n",
        "for k, v in df_dict.items():\n",
        "  cc_column = cc_list[int(k[-1])]+' domains'\n",
        "  cc = cc_list[int(k[-1])]\n",
        "  # print(cc_column, cc)\n",
        "  urls = pd.read_csv(gdrive_path+'url_lists/'+cc_list[int(k[-1])]+'_urls.csv')[cc_column].values.tolist()\n",
        "  domains = {extract_main_domain(url) for url in urls if extract_main_domain(url) is not None}\n",
        "  matching_links = [link for link in v.url if extract_main_domain(link) in domains]\n",
        "  # update the dataframe\n",
        "  v['domain'] = v['url'].apply(extract_main_domain)\n",
        "\n",
        "# check one of the dataframes\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "dFCVEXuJpF_U"
      },
      "id": "dFCVEXuJpF_U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the analysis\n",
        "\n",
        "Import stopwords dictionaries for the 4 langauges we work with.\n",
        "It is good to import all of them in our case, because many websites have sections is English, German or French even when this is not the main language of the website."
      ],
      "metadata": {
        "id": "inCepASp67ru"
      },
      "id": "inCepASp67ru"
    },
    {
      "cell_type": "code",
      "source": [
        "# load a list of 'stopwords' function\n",
        "def get_stopwords_list(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        stopwords = f.readlines()\n",
        "        stop_set = set(m.strip() for m in stopwords)\n",
        "        return list(frozenset(stop_set))"
      ],
      "metadata": {
        "id": "_bCxFJzY69_b"
      },
      "id": "_bCxFJzY69_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the stopwords list for all languages (using cc_list previously defined)\n",
        "# cc_list = ['NL', 'UK', 'DE', 'FR'] # remove the hashtag from this line to uncomment this code and make it run\n",
        "\n",
        "stopwords = [] # empty list to which a list of stopwords will be appended in loop\n",
        "\n",
        "for i in range(len(cc_list)):\n",
        "  stopwords_cc_path = \"/content/cultural-data-analysis/stopwords_archive/\"+cc_list[i]+\".txt\"\n",
        "  stopwords_cc = get_stopwords_list(stopwords_cc_path)\n",
        "  #print(len(stopwords_cc)) # print how many words are in the list\n",
        "  stopwords.extend(stopwords_cc)\n",
        "\n",
        "#print(len(stopwords)) # print how many words are in all stopwords lists"
      ],
      "metadata": {
        "id": "kP-WH-JMXzeM"
      },
      "id": "kP-WH-JMXzeM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you may need to include additional words which you notice as too frequent\n",
        "special_stop_words = ['nbsp', 'nl', 'fr', 'de', 'uk', 'com', 'www', 'lit', ' '] # these might appear frequently as 'terms' in the corpus, so it's good to filter them\n",
        "stopwords_ext = stopwords+special_stop_words"
      ],
      "metadata": {
        "id": "HgNkZORH75QF"
      },
      "id": "HgNkZORH75QF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b5238d41-a6b8-48db-84d9-f6d3bb1054ad",
      "metadata": {
        "id": "b5238d41-a6b8-48db-84d9-f6d3bb1054ad"
      },
      "source": [
        "## 1. Term frequency\n",
        "\n",
        "The cells below will compute a term-matrix and calculate the frequency of each unique word (token) in the corpus\n",
        "\n",
        "This can be done for ALL words in the corpus, or ALL MEANINGFUL words (without so-called stop-words like 'the' or 'het')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7d7865-db1f-42bc-97a0-f901e371a5e5",
      "metadata": {
        "id": "3b7d7865-db1f-42bc-97a0-f901e371a5e5",
        "outputId": "44aa321b-efa6-4324-af92-f06e80927a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(87327,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       terms\n",
              "de                    108181\n",
              "van                    61552\n",
              "en                     58681\n",
              "het                    55170\n",
              "in                     45629\n",
              "...                      ...\n",
              "ontvangstbevestiging       1\n",
              "onttrekking                1\n",
              "boetzelaersborg            1\n",
              "boetzelaer                 1\n",
              "boetselaersborg            1\n",
              "\n",
              "[87317 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-742c16be-7567-4503-8931-46c5965e4062\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <td>108181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>van</th>\n",
              "      <td>61552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>58681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>het</th>\n",
              "      <td>55170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>45629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ontvangstbevestiging</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>onttrekking</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boetzelaersborg</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boetzelaer</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boetselaersborg</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87317 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742c16be-7567-4503-8931-46c5965e4062')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-742c16be-7567-4503-8931-46c5965e4062 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-742c16be-7567-4503-8931-46c5965e4062');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df4f313b-fe81-4863-ba92-69c1fc2246e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df4f313b-fe81-4863-ba92-69c1fc2246e2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df4f313b-fe81-4863-ba92-69c1fc2246e2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"term_freq_df_all\",\n  \"rows\": 87317,\n  \"fields\": [\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 603,\n        \"min\": 1,\n        \"max\": 108181,\n        \"num_unique_values\": 900,\n        \"samples\": [\n          2667,\n          73,\n          1014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# CALCULATE TERM FREQUENCY OF ALL TERMS\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# convert the text documents into a matrix of token (word) counts\n",
        "cvec_all = CountVectorizer().fit(df0.text) #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "df_matrix_all = cvec_all.transform(df0.text) #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "df_all = np.sum(df_matrix_all,axis=0)\n",
        "terms = np.squeeze(np.asarray(df_all))\n",
        "# print the 'shape' of the matrix - it should indicate the number of unique terms\n",
        "print(terms.shape)\n",
        "term_freq_df_all = pd.DataFrame([terms],columns=cvec_all.get_feature_names_out()).transpose() #term_freq_df is with stopwords\n",
        "term_freq_df_all.columns = ['terms']\n",
        "# show the first ten words [:10];\n",
        "# change the values in the brackets to show 30th-40th words [30:40]\n",
        "# or show the last ten words [:-10]\n",
        "term_freq_df_all.sort_values(by='terms', ascending=False).iloc[:-10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e317c18-cf12-48e6-a4db-57b3a99fde06",
      "metadata": {
        "id": "4e317c18-cf12-48e6-a4db-57b3a99fde06",
        "outputId": "ac44caa5-bced-4fae-da1b-72c7c9eb7315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'daren', 'hadn', 'herse', 'himse', 'itse', 'mayn', 'mightn', 'mustn', 'myse', 'needn', 'oughtn', 'shan'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1216 entries' term frequency calculated\n",
            "2433 entries' term frequency calculated\n",
            "3650 entries' term frequency calculated\n",
            "4867 entries' term frequency calculated\n",
            "6083 entries' term frequency calculated\n",
            "7300 entries' term frequency calculated\n",
            "8517 entries' term frequency calculated\n",
            "9734 entries' term frequency calculated\n",
            "10951 entries' term frequency calculated\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            terms\n",
              "kasteel     17702\n",
              "museum       7290\n",
              "jaar         4568\n",
              "onze         4167\n",
              "uur          3858\n",
              "landgoed     3806\n",
              "huis         3506\n",
              "bezoek       3319\n",
              "muiderslot   3086\n",
              "zien         2800"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd18f481-6c65-4701-80c0-c868261262e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kasteel</th>\n",
              "      <td>17702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>museum</th>\n",
              "      <td>7290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jaar</th>\n",
              "      <td>4568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>onze</th>\n",
              "      <td>4167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uur</th>\n",
              "      <td>3858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>landgoed</th>\n",
              "      <td>3806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huis</th>\n",
              "      <td>3506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bezoek</th>\n",
              "      <td>3319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>muiderslot</th>\n",
              "      <td>3086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zien</th>\n",
              "      <td>2800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd18f481-6c65-4701-80c0-c868261262e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd18f481-6c65-4701-80c0-c868261262e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd18f481-6c65-4701-80c0-c868261262e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8b840e0c-6443-4159-86f8-067db30fe1bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b840e0c-6443-4159-86f8-067db30fe1bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8b840e0c-6443-4159-86f8-067db30fe1bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"term_freq_df_stopped\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4497,\n        \"min\": 2800,\n        \"max\": 17702,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          3086,\n          7290,\n          3806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# CALCULATE TERM FREQUENCY WITHOUT STOP-WORDS\n",
        "\n",
        "#cvec_stopped = CountVectorizer(max_df=0.5, token_pattern=r'(?u)\\b[A-Za-z]{2,}\\b') # max_df could in theory automatically filter stopwords\n",
        "cvec_stopped = CountVectorizer(stop_words=stopwords_ext, token_pattern=r'(?u)\\b[A-Za-z]{2,}\\b') # token pattern recognizes only words which are made of letters, and longer than 1 character\n",
        "cvec_stopped.fit(df0.text) #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "document_matrix = cvec_stopped.transform(df0.text) #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "term_batches = np.linspace(0,document_matrix.shape[0],10).astype(int)\n",
        "i=0\n",
        "df_stopped = []\n",
        "while i < len(term_batches)-1:\n",
        "    batch_result = np.sum(document_matrix[term_batches[i]:term_batches[i+1]].toarray(),axis=0)\n",
        "    df_stopped.append(batch_result)\n",
        "    print(term_batches[i+1],\"entries' term frequency calculated\")\n",
        "    i += 1\n",
        "\n",
        "terms_stopped = np.sum(df_stopped,axis=0)\n",
        "#print(terms_stopped.shape)\n",
        "term_freq_df_stopped = pd.DataFrame([terms_stopped],columns=cvec_stopped.get_feature_names_out()).transpose()\n",
        "term_freq_df_stopped.columns = ['terms']\n",
        "term_freq_df_stopped.sort_values(by='terms', ascending=False).iloc[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Term frequency for specific terms"
      ],
      "metadata": {
        "id": "WxJd9MXcViMI"
      },
      "id": "WxJd9MXcViMI"
    },
    {
      "cell_type": "code",
      "source": [
        "search_word = 'kasteel' # Change this to the word you want to search for\n",
        "\n",
        "if search_word in term_freq_df_stopped.index: # check if the words exists;\n",
        "    frequency = term_freq_df_stopped.loc[search_word, 'terms']\n",
        "    print(f\"The word '{search_word}' appears {frequency} times in the current corpus.\")\n",
        "elif search_word in stopwords_ext:\n",
        "    # If not found in stopped, maybe it was a stop word, so check all terms\n",
        "    frequency = term_freq_df_all.loc[search_word, 'terms']\n",
        "    print(f\"The word '{search_word}' was filtered out as a stopword. Its total frequency is {frequency} times.\")\n",
        "else:\n",
        "    print(f\"The word '{search_word}' was not found in the corpus.\")"
      ],
      "metadata": {
        "id": "sPRXo8GKUXcA"
      },
      "id": "sPRXo8GKUXcA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "09be655e-553d-4f2f-8993-9a4fbe63c0aa",
      "metadata": {
        "id": "09be655e-553d-4f2f-8993-9a4fbe63c0aa"
      },
      "source": [
        "### 1.2 TF-IDF vectorization\n",
        "\n",
        "- What is TF/IDF (term frequency / inverse document frequency)? https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002e51e5-ccc0-41c7-9e8c-35d2c794368b",
      "metadata": {
        "id": "002e51e5-ccc0-41c7-9e8c-35d2c794368b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords_ext, token_pattern=r'(?u)\\b[A-Za-z]{2,}\\b')\n",
        "# Fit and transform the text data\n",
        "tfidf_matrix = vectorizer.fit_transform(df0['text']) #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "# Add filenames as index\n",
        "tfidf_df.index = df0['domain'] #### CHANGE df0 TO THE DATAFRAME YOU ANALYSE\n",
        "# Print the TF-IDF DataFrame\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b73181-9d99-4d60-a272-b4c1bb07ae8c",
      "metadata": {
        "id": "54b73181-9d99-4d60-a272-b4c1bb07ae8c"
      },
      "outputs": [],
      "source": [
        "# Function to transform the wide TF-IDF DataFrame to a long format\n",
        "def create_long_tfidf_df_efficiently(tfidf_wide_df):\n",
        "    data = []\n",
        "    for domain, row in tfidf_wide_df.iterrows():\n",
        "        # Get non-zero TF-IDF scores and their corresponding terms to reduce data processing\n",
        "        active_terms = row[row > 0]\n",
        "        for term, tfidf_score in active_terms.items():\n",
        "            data.append({'document': domain, 'term': term, 'tfidf': tfidf_score})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Reorganize the DataFrame from wide to long format using the efficient function\n",
        "tfidf_df = create_long_tfidf_df_efficiently(tfidf_df)\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "\n",
        "# Terms in this list will get a red dot in the visualization\n",
        "term_list = ['kasteel', 'huis', 'children'] # write key terms here"
      ],
      "metadata": {
        "id": "aHP_PD1Z9IBX"
      },
      "id": "aHP_PD1Z9IBX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4308bb87"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "# Calculate top 10 TF-IDF terms per domain\n",
        "top_tfidf_plus = tfidf_df.groupby('document').apply(lambda x: x.nlargest(10, 'tfidf')).reset_index(drop=True)\n",
        "\n",
        "# Add 'rank' based on tfidf score within each document\n",
        "top_tfidf_plus['rank'] = top_tfidf_plus.groupby('document')['tfidf'].rank(method='first', ascending=False).astype(int)\n",
        "\n",
        "# adding a little randomness to break ties in term ranking\n",
        "top_tfidf_plusRand = top_tfidf_plus.copy()\n",
        "top_tfidf_plusRand['tfidf'] = top_tfidf_plusRand['tfidf'] + np.random.rand(top_tfidf_plus.shape[0])*0.0001\n",
        "\n",
        "# Define the base Altair chart\n",
        "base = alt.Chart(top_tfidf_plusRand).encode(\n",
        "    x=alt.X('rank:O', axis=alt.Axis(title='Rank (Top 10 Terms)')),\n",
        "    y=alt.Y('document:N', axis=alt.Axis(title='Domain'))\n",
        ").transform_window(\n",
        "    rank=\"rank()\",\n",
        "    sort=[alt.SortField(\"tfidf\", order=\"descending\")],\n",
        "    groupby=[\"document\"]\n",
        ")\n",
        "\n",
        "# Create the heatmap layer\n",
        "heatmap = base.mark_rect().encode(\n",
        "    color=alt.Color('tfidf:Q', scale=alt.Scale(scheme='yellowgreenblue'), title='TF-IDF Score')\n",
        ")\n",
        "\n",
        "# Create the text layer with white text\n",
        "text = base.mark_text(baseline='middle').encode(\n",
        "    text='term:N',\n",
        "    color=alt.value('white') # Explicitly set text color to white\n",
        ")\n",
        "\n",
        "# Combine the heatmap and text layers and set properties\n",
        "chart = (heatmap + text).properties(\n",
        "    title='Top 10 TF-IDF Terms per Domain',\n",
        "    width=600,\n",
        "    height=alt.Step(25) # Adjust height based on number of documents\n",
        ")\n",
        "\n",
        "chart"
      ],
      "id": "4308bb87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86cca17c"
      },
      "source": [
        "#inspect problems by printing the entire website (document)\n",
        "\n",
        "document = 'artland.top' # replace with one of the website domains on the left\n",
        "\n",
        "print(\"TF-IDF entries for \", document, \": \")\n",
        "display(tfidf_df[tfidf_df['document'] == document].sort_values(by='tfidf', ascending=False))\n",
        "\n",
        "print(\"\\nOriginal text entries for\", document, \": \")\n",
        "# Filter the original DataFrame 'df' for the domain 'kasteeltuinen.nl'\n",
        "domain_text = df0[df0['domain'] == document]['text'].str.cat(sep=' ')\n",
        "print(domain_text)"
      ],
      "id": "86cca17c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Word2Vec model\n",
        "\n",
        "Vectorizing the corpus with word2vec model\n",
        "https://en.wikipedia.org/wiki/Word2vec"
      ],
      "metadata": {
        "id": "xr96f76CWx4Y"
      },
      "id": "xr96f76CWx4Y"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "4RIgZXmuW6Tt"
      },
      "id": "4RIgZXmuW6Tt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "GsDntAtyX6VW"
      },
      "id": "GsDntAtyX6VW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# X is a list of tokenized texts (i.e. list of lists of tokens)\n",
        "X = [word_tokenize(item) for item in df0.text.tolist()] # replace df0 with a dataframe you are analysing\n",
        "#print(X[0:3])\n",
        "model = gensim.models.Word2Vec(X, min_count=6, vector_size=200) # min_count: how many times a word appears in the corpus; size: number of dimensions"
      ],
      "metadata": {
        "id": "Uhm_Fz0eXjjQ"
      },
      "id": "Uhm_Fz0eXjjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe keywords that may be characteristic in the corpus on heritage homes, such as 'castle', 'garden', 'party', 'princess'; try also words related to less obvious themes, like 'servant'\n",
        "\n",
        "You can ask for 'negative' or 'positive' similarity, and explore how these bring up terms that are opposite to the meaning in a variety of ways.\n"
      ],
      "metadata": {
        "id": "TxgCXzxKX_7M"
      },
      "id": "TxgCXzxKX_7M"
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"kasteel\"], topn=12)"
      ],
      "metadata": {
        "id": "v7OWumJgX1E5"
      },
      "id": "v7OWumJgX1E5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=[\"tuin\"], topn=12)"
      ],
      "metadata": {
        "id": "MsfSD5tNYIns"
      },
      "id": "MsfSD5tNYIns",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(negative=[\"baron\"], topn=12)"
      ],
      "metadata": {
        "id": "6VVnnjwFYNF6"
      },
      "id": "6VVnnjwFYNF6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Collocations"
      ],
      "metadata": {
        "id": "2nFPgMYkiygf"
      },
      "id": "2nFPgMYkiygf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Analyze specific collocations"
      ],
      "metadata": {
        "id": "COojp_VZphQW"
      },
      "id": "COojp_VZphQW"
    },
    {
      "cell_type": "code",
      "source": [
        "# define vectorization functions\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "from itertools import islice\n",
        "\n",
        "# SCI-KIT method, produces lists of co-occurencies for specific terms\n",
        "def vectorize_text(df, column):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(df[column])\n",
        "    return X, vectorizer\n",
        "\n",
        "def find_collocations(text, target_words):\n",
        "    words = text.split()\n",
        "    collocations = []\n",
        "    for i in range(len(words) - 1):\n",
        "        if words[i] in target_words:\n",
        "            collocations.append((words[i], words[i + 1]))\n",
        "        if words[i + 1] in target_words:\n",
        "            collocations.append((words[i + 1], words[i]))\n",
        "    return collocations\n",
        "\n",
        "def get_frequent_collocations(df, column, most_frequent_words):\n",
        "    collocations = []\n",
        "    for text_content in df[column]:\n",
        "        collocations.extend(find_collocations(text_content, most_frequent_words))\n",
        "    collocation_counts = Counter(collocations)\n",
        "    frequent_collocations = {}\n",
        "    for word in most_frequent_words:\n",
        "        word_collocations = {collocation: count for collocation, count in collocation_counts.items() if word in collocation}\n",
        "        frequent_collocations[word] = dict(islice(Counter(word_collocations).most_common(20), 20)) # change these two values to get more or less terms\n",
        "    return frequent_collocations\n",
        "\n",
        "def analyze_word_collocations(df, column):\n",
        "    X, vectorizer = vectorize_text(df, column)\n",
        "    most_frequent_words = search_words\n",
        "    frequent_collocations = get_frequent_collocations(df, column, most_frequent_words)\n",
        "    return frequent_collocations"
      ],
      "metadata": {
        "id": "032f9482-879c-43f9-a9cd-3b1ca5d7056c"
      },
      "execution_count": null,
      "outputs": [],
      "id": "032f9482-879c-43f9-a9cd-3b1ca5d7056c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the search term here, analyse whether it appears in the corpus and next to which words (excluding stopwords)"
      ],
      "metadata": {
        "id": "NGX6nGd5YpOH"
      },
      "id": "NGX6nGd5YpOH"
    },
    {
      "cell_type": "code",
      "source": [
        "# search for words from this list or use another list\n",
        "search_words = ['kasteel']"
      ],
      "metadata": {
        "id": "LoJnS9K7h5Kd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LoJnS9K7h5Kd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2657cbe3-aa7e-4e4b-8d68-1d6050cf6f49"
      },
      "outputs": [],
      "source": [
        "collocations = analyze_word_collocations(df0, 'text') # CHANGE df0 TO DATAFRAME YOU ARE ANALYSING"
      ],
      "id": "2657cbe3-aa7e-4e4b-8d68-1d6050cf6f49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fbef5d2-983b-49fa-8924-95abd24b2855"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for word, colloc_dict in collocations.items():\n",
        "   for collocation, count in colloc_dict.items():\n",
        "       #collocation_str = ' '.join(collocation)  # Join collocation words into a single string\n",
        "       data.append([word, collocation[1], count])\n",
        "collocations_df = pd.DataFrame(data, columns=['Word', 'Collocation', 'Count'])\n",
        "print(collocations_df.to_markdown(index=True))"
      ],
      "id": "4fbef5d2-983b-49fa-8924-95abd24b2855"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1. Analyze term frequency and collocation in page titles"
      ],
      "metadata": {
        "id": "EP4227iyZM7m"
      },
      "id": "EP4227iyZM7m"
    },
    {
      "cell_type": "code",
      "source": [
        "# add a column 'page_title' to th dataframe (df0 or df1-3) extracting the value of 'title' key in metadata dictionary in each entry (lambda function)\n",
        "\n",
        "df0['page_title'] = df0['metadata'].apply(lambda x: x.get('title'))\n",
        "df0['page_title'].head()"
      ],
      "metadata": {
        "id": "lwu955g2ZT1e"
      },
      "id": "lwu955g2ZT1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_term = 'baron'\n",
        "total_occurrences = 0\n",
        "\n",
        "print(\"Searching for\", search_term, \":\")\n",
        "for index, title in df0['page_title'].items():\n",
        "    if isinstance(title, str):\n",
        "        # Convert to lowercase for case-insensitive search\n",
        "        title_lower = title.lower()\n",
        "        # Count occurrences in the current title\n",
        "        occurrences_in_title = title_lower.count(search_term)\n",
        "        if occurrences_in_title > 0:\n",
        "            print(title)\n",
        "            total_occurrences += occurrences_in_title\n",
        "\n",
        "print(\"\\nTotal occurrences of\", search_term, \"across all titles: \", total_occurrences)"
      ],
      "metadata": {
        "id": "VFJU-i7BZbJN"
      },
      "id": "VFJU-i7BZbJN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search for words from this list or use another list\n",
        "search_words = ['baron', 'kasteel']"
      ],
      "metadata": {
        "id": "faZlS4sQC64C"
      },
      "id": "faZlS4sQC64C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the collocations in titles\n",
        "collocations = analyze_word_collocations(df0, 'page_title') # CHANGE df0 TO DATAFRAME YOU ARE ANALYSING"
      ],
      "metadata": {
        "id": "fYVU8MuKDJrZ"
      },
      "id": "fYVU8MuKDJrZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for word, colloc_dict in collocations.items():\n",
        "   for collocation, count in colloc_dict.items():\n",
        "       #collocation_str = ' '.join(collocation)  # Join collocation words into a single string\n",
        "       data.append([word, collocation[1], count])\n",
        "collocations_df = pd.DataFrame(data, columns=['Word', 'Collocation', 'Count'])\n",
        "print(collocations_df.to_markdown(index=True))"
      ],
      "metadata": {
        "id": "7dBtWwh_DVEK"
      },
      "id": "7dBtWwh_DVEK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08144921-d7be-45ed-8795-1c085fb2640b"
      },
      "source": [
        "### 2.2 Analyse collocations in sentences"
      ],
      "id": "08144921-d7be-45ed-8795-1c085fb2640b"
    },
    {
      "cell_type": "code",
      "source": [
        "#function to remove non-ascii characters\n",
        "def _removeNonAscii(s): return \"\".join(i for i in s if ord(i)<128)"
      ],
      "metadata": {
        "id": "0SuPUQ_4VrfT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0SuPUQ_4VrfT"
    },
    {
      "cell_type": "code",
      "source": [
        "# import the advanced Natural Language Processing (NLP) library\n",
        "# which we will use to analze the grammatical structure\n",
        "import spacy"
      ],
      "metadata": {
        "id": "ijzGDgoRAHN3"
      },
      "id": "ijzGDgoRAHN3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the suitable language pipeline\n",
        "# Dutch: nl_core_news_sm\n",
        "# French: fr_core_news_sm\n",
        "# German: de_core_news_sm\n",
        "# English: en_core_web_sm (available by default)\n",
        "!python -m spacy download nl_core_news_sm"
      ],
      "metadata": {
        "id": "55G_5i9IAs1b"
      },
      "id": "55G_5i9IAs1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('nl_core_news_sm') # change to FR/DE/EN code module, see names above"
      ],
      "metadata": {
        "id": "pqCDLM2KAce0"
      },
      "id": "pqCDLM2KAce0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatize the text in 'text' column of the dataframe\n",
        "https://en.wikipedia.org/wiki/Lemmatization"
      ],
      "metadata": {
        "id": "kl-wdZc2L66X"
      },
      "id": "kl-wdZc2L66X"
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "#function to clean and lemmatize text\n",
        "def clean_documents(text):\n",
        "    # Ensure text is a string to prevent errors with non-string inputs\n",
        "    text = str(text)\n",
        "\n",
        "    # Remove all non-alphabetic characters (incl. punctuation, numbers, etc.)\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "\n",
        "    # Replace multiple spaces with a single space and strip leading/trailing spaces.\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "\n",
        "    # If the text becomes empty after cleaning (e.g., if it was only punctuation), return an empty list\n",
        "    if not cleaned_text:\n",
        "        return []\n",
        "\n",
        "    # lemmatize the text with spacy\n",
        "    doc = nlp(cleaned_text, disable=['parser','ner'])\n",
        "    # Get lemmas, convert to lowercase, and filter out any empty strings that might arise\n",
        "    # token.lemma_.strip() ensures no whitespace-only strings are included\n",
        "    lemma = [token.lemma_.lower() for token in doc if token.lemma_.strip()]\n",
        "    return lemma"
      ],
      "metadata": {
        "id": "yeR7duSYWD9p"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yeR7duSYWD9p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize the text in .text column\n",
        "lemmatized = df0.text.map(clean_documents) # CHANGE df0 TO THE DATAFRAME YOU ARE ANALYSING\n",
        "lemmatized.head()"
      ],
      "metadata": {
        "id": "7VsB2yq1WObL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7VsB2yq1WObL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the list of lists into one list + remove stopwords\n",
        "unlist_documents = [word for sublist in lemmatized for word in sublist if word not in stopwords_ext]"
      ],
      "metadata": {
        "id": "IS3V0pl3Xksv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IS3V0pl3Xksv"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "Hbkku34SfpU1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Hbkku34SfpU1"
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate bigrams and trigrams\n",
        "bigrams = nltk.collocations.BigramAssocMeasures()\n",
        "trigrams = nltk.collocations.TrigramAssocMeasures()"
      ],
      "metadata": {
        "id": "3IaXW0GXX4X2"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3IaXW0GXX4X2"
    },
    {
      "cell_type": "code",
      "source": [
        "# identify all collocations in the flat list of words from all documents\n",
        "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(unlist_documents)\n",
        "trigramFinder = nltk.collocations.TrigramCollocationFinder.from_words(unlist_documents)"
      ],
      "metadata": {
        "id": "6L2vI56MX9ps"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6L2vI56MX9ps"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate basic frequency"
      ],
      "metadata": {
        "id": "mRSuATcHYm0U"
      },
      "id": "mRSuATcHYm0U"
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_freq = bigramFinder.ngram_fd.items()"
      ],
      "metadata": {
        "id": "W9XCfughYim0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W9XCfughYim0"
    },
    {
      "cell_type": "code",
      "source": [
        "bigramFreqTable = pd.DataFrame(list(bigram_freq), columns=['bigram','freq']).sort_values(by='freq', ascending=False)"
      ],
      "metadata": {
        "id": "4dCLatTKfJDe"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4dCLatTKfJDe"
    },
    {
      "cell_type": "code",
      "source": [
        "bigramFreqTable.head().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "NHE_sQvofMKw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NHE_sQvofMKw"
    },
    {
      "cell_type": "code",
      "source": [
        "# compute basic trigrams frequency\n",
        "trigram_freq = trigramFinder.ngram_fd.items()\n",
        "trigramFreqTable = pd.DataFrame(list(trigram_freq), columns=['trigram','freq']).sort_values(by='freq', ascending=False)\n",
        "trigramFreqTable[:10]"
      ],
      "metadata": {
        "id": "pYTAOfQGhfY3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pYTAOfQGhfY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fee7258d"
      },
      "source": [
        "Search for a specific term in bigram & trigram frequency table:"
      ],
      "id": "fee7258d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f75d31ba"
      },
      "source": [
        "search_term = 'kasteel'"
      ],
      "id": "f75d31ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_bigrams_for_term = bigramFreqTable[bigramFreqTable['bigram'].apply(lambda x: search_term in x)]\n",
        "\n",
        "display(filtered_bigrams_for_term.head(10))"
      ],
      "metadata": {
        "id": "YjifGsX2OlGU"
      },
      "id": "YjifGsX2OlGU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a0e9c0a"
      },
      "source": [
        "filtered_trigrams_for_term = trigramFreqTable[trigramFreqTable['trigram'].apply(lambda x: search_term in x)]\n",
        "\n",
        "display(filtered_trigrams_for_term.head(10))"
      ],
      "id": "3a0e9c0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Meaningful bi- and tri-grams\n",
        "\n",
        "Identify birgrams and trigramms by filtering adjectives and nouns based on an nltk functionality"
      ],
      "metadata": {
        "id": "W8JjofCAYNdC"
      },
      "id": "W8JjofCAYNdC"
    },
    {
      "cell_type": "code",
      "source": [
        "#function to filter for ADJ/NN bigrams\n",
        "def rightTypes(ngram):\n",
        "    for word in ngram:\n",
        "        if word in stopwords_ext:\n",
        "            return False\n",
        "    acceptable_types = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
        "    second_type = ('NN', 'NNS', 'NNP', 'NNPS')\n",
        "    tags = nltk.pos_tag(ngram)\n",
        "    if tags[0][1] in acceptable_types and tags[1][1] in second_type:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "OryUdGaYYMGs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OryUdGaYYMGs"
    },
    {
      "cell_type": "code",
      "source": [
        "#filter bigrams\n",
        "\n",
        "### WARNING: THIS MAY TAKE A LONGER TIME TO COMPLETE (~3min)\n",
        "filtered_bi = bigramFreqTable[bigramFreqTable.bigram.map(lambda x: rightTypes(x))]"
      ],
      "metadata": {
        "id": "a6HFZOAafcqP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "a6HFZOAafcqP"
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_bi[:10]"
      ],
      "metadata": {
        "id": "DoEO44Tzf-i8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DoEO44Tzf-i8"
    },
    {
      "cell_type": "code",
      "source": [
        "#filter trigrams\n",
        "\n",
        "### WARNING: THIS MAY TAKE A LONGER TIME TO COMPLETE (~3min)\n",
        "filtered_tri = trigramFreqTable[trigramFreqTable.trigram.map(lambda x: rightTypes(x))]"
      ],
      "metadata": {
        "id": "6zLPr-iOP1gK"
      },
      "id": "6zLPr-iOP1gK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tri[:10]"
      ],
      "metadata": {
        "id": "LITa7UDMSs-Y"
      },
      "id": "LITa7UDMSs-Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search for a specific term in FILTERED bigram & trigram frequency tables:\n"
      ],
      "metadata": {
        "id": "VOgCjJHWS7Q8"
      },
      "id": "VOgCjJHWS7Q8"
    },
    {
      "cell_type": "code",
      "source": [
        "search_term = 'kasteel'"
      ],
      "metadata": {
        "id": "1aGcDf34S5lr"
      },
      "id": "1aGcDf34S5lr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_bigrams_for_term = filtered_bi[filtered_bi['bigram'].apply(lambda x: search_term in x)]\n",
        "\n",
        "display(filtered_bigrams_for_term.head(10))"
      ],
      "metadata": {
        "id": "aD_kV1cNS4jA"
      },
      "id": "aD_kV1cNS4jA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_trigrams_for_term = filtered_tri[filtered_tri['trigram'].apply(lambda x: search_term in x)]\n",
        "\n",
        "display(filtered_trigrams_for_term.head(10))"
      ],
      "metadata": {
        "id": "Qja0oHfiTWAO"
      },
      "id": "Qja0oHfiTWAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use advanced statistical methods like the Chi-Square to identify meaninful collocations\n",
        "https://en.wikipedia.org/wiki/Chi-squared_test"
      ],
      "metadata": {
        "id": "LGPGqH0Xj98T"
      },
      "id": "LGPGqH0Xj98T"
    },
    {
      "cell_type": "code",
      "source": [
        "# filter bigrams using chi-square\n",
        "bigramChiTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n",
        "bigramChiTable.head()"
      ],
      "metadata": {
        "id": "j8IPPymTjaql"
      },
      "execution_count": null,
      "outputs": [],
      "id": "j8IPPymTjaql"
    },
    {
      "cell_type": "code",
      "source": [
        "# find meaningful trigrams by filtering basic frequency table\n",
        "# function to filter trigrams\n",
        "def rightTypesTri(ngram):\n",
        "    if '-pron-' in ngram or '' in ngram or ' 'in ngram or '  ' in ngram or 't' in ngram:\n",
        "        return False\n",
        "    for word in ngram:\n",
        "        if word in stopwords_ext:\n",
        "            return False\n",
        "    first_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
        "    third_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
        "    tags = nltk.pos_tag(ngram)\n",
        "    if tags[0][1] in first_type and tags[2][1] in third_type:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "W5wqPcjzh_lW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W5wqPcjzh_lW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-sqare frequency calculation for trigrams\n",
        "trigramChiTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.chi_sq)), columns=['trigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n",
        "trigramChiTable.head(10)"
      ],
      "metadata": {
        "id": "OIr3r7XBkaqF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OIr3r7XBkaqF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Topic Modelling"
      ],
      "metadata": {
        "id": "PgNuFIbceN1G"
      },
      "id": "PgNuFIbceN1G"
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.feature_extraction.text as text\n",
        "\n",
        "# min_df: ignore words occurring in fewer than `n` documents\n",
        "# stop_words: ignore very common words (\"the\", \"and\", \"or\", \"to\", ...)\n",
        "vec = text.CountVectorizer(lowercase=True, min_df=100, stop_words=stopwords_ext)\n",
        "dtm = vec.fit_transform(df0['text']) # CHANGE df0 TO THE DATAFRAME YOU ARE ANALYSING"
      ],
      "metadata": {
        "id": "9YyJGfJh-STX"
      },
      "id": "9YyJGfJh-STX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of document-term matrix: {dtm.shape}. '\n",
        "      f'Number of tokens {dtm.sum()}')"
      ],
      "metadata": {
        "id": "plChqYaT-TY6",
        "outputId": "8995b48d-1da1-47f3-b8f0-517e6dcbbd1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "plChqYaT-TY6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of document-term matrix: (10951, 1449). Number of tokens 667527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.decomposition as decomposition\n",
        "NUM_TOPICS = 10\n",
        "lda_model = decomposition.LatentDirichletAllocation(\n",
        "    n_components=NUM_TOPICS, learning_method='online', random_state=1)\n",
        "lda_Z = lda_model.fit_transform(dtm)\n",
        "print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
        "\n",
        "document_topic_distributions = lda_model.fit_transform(dtm)\n",
        "\n",
        "top_n=10\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "  print(\"Topic %d:\" % (idx))\n",
        "  print([(vec.get_feature_names_out()[i], topic[i])\n",
        "  for i in topic.argsort()[:-top_n - 1:-1]])"
      ],
      "metadata": {
        "id": "nzRlq3WCeSC_",
        "outputId": "9e22c382-bde8-4821-e15b-067a60da2984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nzRlq3WCeSC_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10951, 10)\n",
            "Topic 0:\n",
            "[('kasteel', np.float64(4101.640288488984)), ('arcen', np.float64(2672.781493046379)), ('kasteeltuinen', np.float64(1694.7489201496946)), ('park', np.float64(1397.0720569350326)), ('slot', np.float64(1035.0133196429865)), ('zuylen', np.float64(736.943361875806)), ('loevestein', np.float64(729.5426883199992)), ('schlossgÃ¤rten', np.float64(700.957166941864)), ('heeswijk', np.float64(674.5268436303486)), ('tuinen', np.float64(600.2164955599784))]\n",
            "Topic 1:\n",
            "[('kasteel', np.float64(5343.903246167998)), ('huis', np.float64(2646.805228065219)), ('gevonden', np.float64(1162.9475621763222)), ('museum', np.float64(1021.3593938902801)), ('bergh', np.float64(904.3967183847965)), ('nienoord', np.float64(899.6456678324004)), ('doorn', np.float64(767.9606358397521)), ('amerongen', np.float64(717.9832861250422)), ('dekema', np.float64(691.3891992164619)), ('online', np.float64(511.50544201251256))]\n",
            "Topic 2:\n",
            "[('castle', np.float64(2040.8779141280015)), ('cookies', np.float64(1337.8304720757556)), ('museum', np.float64(819.5536698071709)), ('wij', np.float64(766.5562774393175)), ('contact', np.float64(757.2164516471859)), ('stichting', np.float64(668.8286295129095)), ('vragen', np.float64(591.3371597094153)), ('privacy', np.float64(586.1323986605305)), ('informatie', np.float64(536.6910276334629)), ('gegevens', np.float64(524.0853360098333))]\n",
            "Topic 3:\n",
            "[('2024', np.float64(3770.6459003090768)), ('2023', np.float64(2244.5577243045927)), ('lees', np.float64(1799.7939533127233)), ('2022', np.float64(1618.6936779988357)), ('verder', np.float64(1362.335305446391)), ('2020', np.float64(1217.2716604904138)), ('2021', np.float64(966.1511880455415)), ('workshop', np.float64(845.1966993756472)), ('december', np.float64(807.0825368449488)), ('duivenvoorde', np.float64(751.1836082676253))]\n",
            "Topic 4:\n",
            "[('fundatie', np.float64(3017.2301591149435)), ('museum', np.float64(2835.3825700610782)), ('collection', np.float64(2330.590095178049)), ('read', np.float64(1849.0119667087736)), ('collectie', np.float64(1381.9964274161632)), ('garden', np.float64(1198.5287163230098)), ('kasteel', np.float64(883.2887120480214)), ('hannema', np.float64(781.9156940470615)), ('nijenhuis', np.float64(775.9054634997187)), ('titel', np.float64(747.3835031012838))]\n",
            "Topic 5:\n",
            "[('00', np.float64(5546.0635208553695)), ('uur', np.float64(3772.1068319680826)), ('30', np.float64(2089.017337417229)), ('15', np.float64(1764.7071479078325)), ('gratis', np.float64(1661.065060178584)), ('12', np.float64(1487.7716536161477)), ('16', np.float64(1389.100335983283)), ('kinderen', np.float64(1361.7691227766245)), ('11', np.float64(1333.1566254363083)), ('17', np.float64(1230.6770935844934))]\n",
            "Topic 6:\n",
            "[('muiderslot', np.float64(3230.0624673516722)), ('hoensbroek', np.float64(1826.41928682882)), ('kastelen', np.float64(1226.161575026357)), ('elk', np.float64(1132.147922636221)), ('kasteel', np.float64(992.0688957291196)), ('resultaten', np.float64(895.8932158952167)), ('search', np.float64(742.3562115575281)), ('ontdek', np.float64(706.5197629161098)), ('geschiedenis', np.float64(666.6045120712103)), ('terug', np.float64(656.2837077300779))]\n",
            "Topic 7:\n",
            "[('museum', np.float64(2505.697536093572)), ('ijsselstein', np.float64(1954.7886460380225)), ('zien', np.float64(1380.8306096789872)), ('tentoonstelling', np.float64(1322.193850207289)), ('werk', np.float64(1308.015630835606)), ('eeuw', np.float64(1132.0753741521128)), ('kunst', np.float64(993.4014000298375)), ('jaar', np.float64(898.7782592397352)), ('foto', np.float64(860.8651513038169)), ('nieuwe', np.float64(845.6921701840025))]\n",
            "Topic 8:\n",
            "[('landgoed', np.float64(2854.905381513044)), ('bezoek', np.float64(1708.7961625936853)), ('natuur', np.float64(1218.4311275041389)), ('heerlen', np.float64(1204.9179463469773)), ('historisch', np.float64(1064.1643716705355)), ('landschap', np.float64(987.6844356288477)), ('goud', np.float64(883.0955500257535)), ('tuin', np.float64(863.6531489950108)), ('kasteel', np.float64(832.8015039653575)), ('stichting', np.float64(806.51756150922))]\n",
            "Topic 9:\n",
            "[('kasteel', np.float64(4408.293106005766)), ('route', np.float64(1914.599301578567)), ('onze', np.float64(1789.4543525015113)), ('wij', np.float64(1429.087253414112)), ('mee', np.float64(1331.6451093576172)), ('kunt', np.float64(1128.566878008944)), ('maken', np.float64(1113.2434620962988)), ('wel', np.float64(1004.2491591737673)), ('kun', np.float64(1002.1530525553156)), ('waar', np.float64(990.4120510730827))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_top_words = 12\n",
        "no_top_documents = 5\n",
        "lda_H = lda_model.components_\n",
        "tf_feature_names = vec.get_feature_names_out()\n",
        "\n",
        "def display_topics(H, Z, feature_names, docs, no_top_words, no_top_documents):\n",
        "    for idx, topic in enumerate(H):\n",
        "        print(\"Topic %d:\" % (idx))\n",
        "        print(\"KEYWORDS\", \" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        top_doc_indices = np.argsort( Z[:,\n",
        "                                        idx] )[::-1][0:no_top_documents]\n",
        "        # good for checking which documents are the most characteristic for certain topics\n",
        "        for doc_index in top_doc_indices:\n",
        "            print(\"TOP DOCS\", docs[doc_index])\n",
        "\n",
        "display_topics(lda_H, lda_Z, tf_feature_names, df0['url'].tolist(), no_top_words, no_top_documents)"
      ],
      "metadata": {
        "id": "t2cF-DTp-Pa_",
        "outputId": "aabf6838-f663-4bb1-8220-ba220e5bc020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t2cF-DTp-Pa_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "KEYWORDS kasteel arcen kasteeltuinen park slot zuylen loevestein schlossgÃ¤rten heeswijk tuinen jullie gardens\n",
            "TOP DOCS http://slotzuylen.nl/locatie/slot-zuylen/\n",
            "TOP DOCS https://www.slotloevestein.nl/en/contact/\n",
            "TOP DOCS https://kasteelteylingen.nl/bestuur/\n",
            "TOP DOCS https://www.kasteeltuinen.nl/de/events/geschenkidee-fuer-ihre-mitarbeiter/\n",
            "TOP DOCS https://www.kasteeltuinen.nl/de/die-schoenste-sehenswuerdigkeit-in-arcen/\n",
            "Topic 1:\n",
            "KEYWORDS kasteel huis gevonden museum bergh nienoord doorn amerongen dekema online bezoek doorwerth\n",
            "TOP DOCS https://www.huisdoorn.nl/ontdek-het-museum/huis-en-park/\n",
            "TOP DOCS https://www.huisdoorn.nl/educatie/\n",
            "TOP DOCS https://www.huisdoorn.nl/en/discover-the-museum/house-and-park/emperor-wilhelm-ii/princess-hermine/\n",
            "TOP DOCS https://www.kasteelamerongen.nl/over-het-kasteel/geschiedenis/\n",
            "TOP DOCS https://www.huisdoorn.nl/de/ueber-uns/unterstuetzen-sie-uns/\n",
            "Topic 2:\n",
            "KEYWORDS castle cookies museum wij contact stichting vragen privacy informatie gegevens gebruiken gebruik\n",
            "TOP DOCS https://www.museumijsselstein.nl/oost-west-thuis-best-marijn/\n",
            "TOP DOCS https://www.museumijsselstein.nl/oost-west-thuis-best-evren/\n",
            "TOP DOCS https://www.museumijsselstein.nl/oost-west-thuis-best-briana/\n",
            "TOP DOCS https://www.museumijsselstein.nl/oost-west-thuis-best-melanie/\n",
            "TOP DOCS https://www.museumijsselstein.nl/oost-west-thuis-best-ryan/\n",
            "Topic 3:\n",
            "KEYWORDS 2024 2023 lees 2022 verder 2020 2021 workshop december duivenvoorde november april\n",
            "TOP DOCS https://kasteelparkborn.nl/steun-het-park/adoptanten/parkiet-papegaai/#Agapornis\n",
            "TOP DOCS https://kasteelparkborn.nl/steun-het-park/adoptanten/parkiet-papegaai/#Edelpapegaai\n",
            "TOP DOCS https://kasteelparkborn.nl/steun-het-park/adoptanten/parkiet-papegaai/#Grijze_roodstaartpapegaai\n",
            "TOP DOCS https://kasteelparkborn.nl/steun-het-park/adoptanten/parkiet-papegaai/#Grote_geelkuifkaketoe\n",
            "TOP DOCS https://kasteelparkborn.nl/steun-het-park/adoptanten/parkiet-papegaai/#Valkparkiet\n",
            "Topic 4:\n",
            "KEYWORDS fundatie museum collection read collectie garden kasteel hannema nijenhuis titel hoogte zwolle\n",
            "TOP DOCS https://www.museumdefundatie.nl/en/accessibility/#menu\n",
            "TOP DOCS https://www.museumdefundatie.nl/en/accessibility/\n",
            "TOP DOCS http://www.museumdefundatie.nl/en/sculpture-garden/2?\n",
            "TOP DOCS https://www.museumdefundatie.nl/en/sculpture-garden/2#menu\n",
            "TOP DOCS https://www.museumdefundatie.nl/en/locations/\n",
            "Topic 5:\n",
            "KEYWORDS 00 uur 30 15 gratis 12 16 kinderen 11 17 14 jaar\n",
            "TOP DOCS https://buitenplaatsbeeckestijn.nl/contact/aanmelden-vrijwilligers/\n",
            "TOP DOCS https://buitenplaatsbeeckestijn.nl/contact/verhuur/\n",
            "TOP DOCS https://www.middachten.nl/openingstijden-en-prijzen/\n",
            "TOP DOCS https://kasteelparkborn.nl/menukaart/\n",
            "TOP DOCS https://www.schierstins.nl/openingstijden/\n",
            "Topic 6:\n",
            "KEYWORDS muiderslot hoensbroek kastelen elk kasteel resultaten search ontdek geschiedenis terug landschap magische\n",
            "TOP DOCS https://www.glk.nl/gebied/landgoed-klein-noordijk#natuur\n",
            "TOP DOCS https://www.glk.nl/gebied/landgoed-klein-noordijk#geschiedenis\n",
            "TOP DOCS https://www.glk.nl/gebied/landgoed-klein-noordijk#locatie-voorzieningen\n",
            "TOP DOCS https://www.glk.nl/gebied/landgoed-klein-noordijk\n",
            "TOP DOCS https://www.glk.nl/gebied/landgoed-oorsprong-en-zilverberg#excursies\n",
            "Topic 7:\n",
            "KEYWORDS museum ijsselstein zien tentoonstelling werk eeuw kunst jaar foto nieuwe grote waar\n",
            "TOP DOCS https://www.museumijsselstein.nl/tentoonstellingen/de-kajuit-jos-verwiel/\n",
            "TOP DOCS https://www.museumijsselstein.nl/tentoonstellingen/de-kajuit-marc-langer/\n",
            "TOP DOCS https://kasteelradboud.nl/de/floris-v-heldhaftige-hervormer-of-strategische-schurk-deel-ii/\n",
            "TOP DOCS https://www.museumijsselstein.nl/do-for-love-efrat-zehavi/\n",
            "TOP DOCS https://www.ruine-ravesteyn.nl/activiteiten/beeldentuin/kunstenaars/2024/Vanhooren.html\n",
            "Topic 8:\n",
            "KEYWORDS landgoed bezoek natuur heerlen historisch landschap goud tuin kasteel stichting toekomst gemeente\n",
            "TOP DOCS https://www.landgoedboschenvaart.nl/bewapening-tegen-droge-perioden\n",
            "TOP DOCS https://www.landgoedboschenvaart.nl/bijdrage-voor-bouwhistorisch-onderzoek\n",
            "TOP DOCS https://www.kasteelhoensbroek.nl/overig/beoordelingen/algemeen-kasteel-vanuit-lucht/\n",
            "TOP DOCS https://www.kasteelhoensbroek.nl/wat-is-er-te-doen/wandelen-rondom-het-kasteel/algemeen-kasteel-vanuit-lucht-2/\n",
            "TOP DOCS https://www.kasteelhoensbroek.nl/onderwijs/voortgezet-onderwijs/schermafbeelding-2017-10-13-om-12-01-12/\n",
            "Topic 9:\n",
            "KEYWORDS kasteel route onze wij mee kunt maken wel kun waar prachtige informatie\n",
            "TOP DOCS https://www.kasteelvalkenburg.nl/meivakantie-uitje-limburg/\n",
            "TOP DOCS https://www.kasteelvalkenburg.nl/contact/\n",
            "TOP DOCS https://www.kasteelvalkenburg.nl/wat-is-er-te-doen/middeleeuws-ridderkampement/\n",
            "TOP DOCS https://www.kasteelvalkenburg.nl/eropuit-zomervakantie/\n",
            "TOP DOCS https://www.kasteelvalkenburg.nl/plan-je-bezoek/route-en-parkeren/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}